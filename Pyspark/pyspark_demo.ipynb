{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame & SQL\n",
    "## <font color=orange>Create</font>\n",
    "* spark.read.option('header', true).option('').csv(path)\n",
    "* spark.createDataFrame(data, schema)\n",
    "### DataType\n",
    "* ArrayType  \n",
    "    - ex. StructField('name', ArrayType(StringType()), True)\n",
    "* MapType: similar python dict  \n",
    "    - ex. StructField('name', MapType(StringType(), StringType()), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/28 21:40:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/28 21:40:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "emptyRDD:  ParallelCollectionRDD[1] at readRDDFromFile at PythonRDD.scala:274\n",
      "Convert DataFrame from emptyRDD\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Demo').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('WARN')\n",
    "# empty RDD\n",
    "emptyRDD = sc.emptyRDD()\n",
    "emptyRDD = sc.parallelize([])\n",
    "print(\"emptyRDD: \",emptyRDD)\n",
    "\n",
    "# Create Schema\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, ArrayType, MapType\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('firstname', StringType(), True),\n",
    "    StructField('middlename', StringType(), True),\n",
    "    StructField('lastname', StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert Dataframe from emptyRDD\n",
    "df = spark.createDataFrame(data=emptyRDD, schema=schema)\n",
    "print('Convert DataFrame from emptyRDD')\n",
    "df.printSchema()\n",
    "\n",
    "# Create DataFrame from schema\n",
    "df2 = spark.createDataFrame([], schema)\n",
    "df2.printSchema()\n",
    "\n",
    "# Create empty DF with no schema\n",
    "df3 = spark.createDataFrame([],StructType([]))\n",
    "df3.printSchema()\n",
    "\n",
    "# convert DF to pandas\n",
    "df_pandas = df.toPandas()\n",
    "type(df_pandas), type(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|{James, , Smith}    |36636|M     |3100  |\n",
      "|{Michael, Rose, }   |40288|M     |4300  |\n",
      "|{Robert, , Williams}|42114|M     |1400  |\n",
      "|{Maria, Anne, Jones}|39192|F     |5500  |\n",
      "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n",
      "+--------------------+------------------------+\n",
      "|name                |OtherInfo               |\n",
      "+--------------------+------------------------+\n",
      "|{James, , Smith}    |{36636, M, 3100, Medium}|\n",
      "|{Michael, Rose, }   |{40288, M, 4300, High}  |\n",
      "|{Robert, , Williams}|{42114, M, 1400, Low}   |\n",
      "|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n",
      "|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n",
      "+--------------------+------------------------+\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|                name|   id|gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|    {James, , Smith}|36636|     M|  3100|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|\n",
      "|{Robert, , Williams}|42114|     M|  1400|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, struct, when, lit\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "    struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)\n",
    "\n",
    "import json\n",
    "schemaFromJson = StructType.fromJson(json.loads(structureSchema.json()))\n",
    "df3 = spark.createDataFrame(\n",
    "    sc.parallelize(structureData), schemaFromJson)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'struct<name:struct<firstname:string,middlename:string,lastname:string>,id:string,gender:string,salary:int>'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.schema.simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/drop `TempView`\n",
    "1. Create\n",
    "  * Global: \n",
    "    ```python\n",
    "    df.createOrReplaceGlobalTempView('TableName')\n",
    "    spark.sql(\"select * from global_temp.TableName\")\n",
    "    ```\n",
    "  * Local:  \n",
    "    ```python\n",
    "    df.createOrReplaceTempView('TableName')\n",
    "    spark.sql(\"select * from TableName)\n",
    "    ```\n",
    "2. Drop\n",
    "  * spark.catalog.dropGlobalTempView('TableName')\n",
    "  * spark.catalog.dropTempView('TableName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name=Row(firstname='James', middlename='', lastname='Smith'), id='36636', gender='M', salary=3100), Row(name=Row(firstname='Michael', middlename='Rose', lastname=''), id='40288', gender='M', salary=4300), Row(name=Row(firstname='Robert', middlename='', lastname='Williams'), id='42114', gender='M', salary=1400), Row(name=Row(firstname='Maria', middlename='Anne', lastname='Jones'), id='39192', gender='F', salary=5500), Row(name=Row(firstname='Jen', middlename='Mary', lastname='Brown'), id='', gender='F', salary=-1)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df2.createOrReplaceTempView('tmp_df2')\n",
    "print(spark.sql('select * from tmp_df2 ').collect())\n",
    "print(spark.catalog.dropTempView('tmp_df2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange>Update</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增欄位 \n",
    "* 新增或替換現有的欄位 withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+------+-------+\n",
      "|                name|   id|gender|salary|new_col|\n",
      "+--------------------+-----+------+------+-------+\n",
      "|    {James, , Smith}|36636|     M|  3100|      0|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|      0|\n",
      "|{Robert, , Williams}|42114|     M|  1400|      0|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|      0|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|      0|\n",
      "+--------------------+-----+------+------+-------+\n",
      "\n",
      "+--------------------+-----+------+------+--------+\n",
      "|                name|   id|gender|salary|  new_co|\n",
      "+--------------------+-----+------+------+--------+\n",
      "|    {James, , Smith}|36636|     M|  3100|over2000|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|over2000|\n",
      "|{Robert, , Williams}|42114|     M|  1400|    1400|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|over2000|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|   error|\n",
      "+--------------------+-----+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "#1 新增欄位輸入值 要用lit\n",
    "df2.withColumn('new_col', lit(0)).show()\n",
    "\n",
    "#2 依現有欄位條件輸入新欄位\n",
    "df2.withColumn('new_co', when(df2.salary<0,'error'). \\\n",
    "                         when(df2.salary==1400, '1400'). \\\n",
    "                         when(df2.salary.between(0,2000),'0-2000'). \\\n",
    "                         otherwise('over2000')).show()\n",
    "#3 新增一個list 轉為spark dataframe 再join\n",
    "# 目前尚未找到類似pd.concat功能\n",
    "\n",
    "id = F.monotonically_increasing_id()\n",
    "row = Row('val', 'num')\n",
    "lt = lt = [row(f'x{i}',i) for i in range(5)]\n",
    "sc_lt = spark.sparkContext.parallelize(lt).toDF()\n",
    "sc_lt = sc_lt.withColumn('matchID', id)\n",
    "df2_new = df2.withColumn('matchID',id)\n",
    "df3 = df2_new.join(sc_lt, df2_new.matchID == sc_lt.matchID, how='inner').drop('matchID')\n",
    "df3 = df3.withColumn('newid', when(df3.id=='',None).otherwise(df3.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 條件篩選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+------+---+---+-----+\n",
      "|              name| id|gender|salary|val|num|newid|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|{Jen, Mary, Brown}|   |     F|    -1| x4|  4| null|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "|                name|   id|gender|salary|val|num|newid|\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "|    {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|   {Michael, Rose, }|40288|     M|  4300| x1|  1|40288|\n",
      "|{Robert, , Williams}|42114|     M|  1400| x2|  2|42114|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500| x3|  3|39192|\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "|             name|   id|gender|salary|val|num|newid|\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "| {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|{Michael, Rose, }|40288|     M|  4300| x1|  1|40288|\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "|              name|   id|gender|salary|val|num|newid|\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "|  {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|{Jen, Mary, Brown}|     |     F|    -1| x4|  4| null|\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|              name| id|gender|salary|val|num|newid|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|{Jen, Mary, Brown}|   |     F|    -1| x4|  4| null|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df3.filter(df3.salary<0).show()\n",
    "# where \n",
    "df3.where(df3.salary>0).show()\n",
    "# between\n",
    "df3.filter(df3.salary.between(3100,4400)).show()\n",
    "# isin\n",
    "df3[df3.salary.isin([3100,-1])].show()\n",
    "# isnull(None) / isnan(非數字)\n",
    "df3.filter(F.isnull('newid')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Rename column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "\n",
    "# Example 1\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()\n",
    "# Example 2   \n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "\n",
    "# Example 3 \n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "    \n",
    "df.select(col(\"name\").cast(schema2),\n",
    "  col(\"dob\"),\n",
    "  col(\"gender\"),\n",
    "  col(\"salary\")) \\\n",
    "    .printSchema()    \n",
    "\n",
    "# Example 4 \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "  col(\"name.middlename\").alias(\"mname\"),\n",
    "  col(\"name.lastname\").alias(\"lname\"),\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()\n",
    "  \n",
    "# Example 5\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()\n",
    "\n",
    "#Example 7\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/13 23:56:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Demo').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "    .option('header',True)\\\n",
    "    .option('inferSchema',True)\\\n",
    "    .csv(\"./archive/CommentsFeb2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- approveDate: string (nullable = true)\n",
      " |-- articleID: string (nullable = true)\n",
      " |-- articleWordCount: string (nullable = true)\n",
      " |-- commentBody: string (nullable = true)\n",
      " |-- commentID: string (nullable = true)\n",
      " |-- commentSequence: string (nullable = true)\n",
      " |-- commentTitle: string (nullable = true)\n",
      " |-- commentType: string (nullable = true)\n",
      " |-- createDate: string (nullable = true)\n",
      " |-- depth: string (nullable = true)\n",
      " |-- editorsSelection: string (nullable = true)\n",
      " |-- inReplyTo: string (nullable = true)\n",
      " |-- newDesk: string (nullable = true)\n",
      " |-- parentID: string (nullable = true)\n",
      " |-- parentUserDisplayName: string (nullable = true)\n",
      " |-- permID: string (nullable = true)\n",
      " |-- picURL: string (nullable = true)\n",
      " |-- printPage: string (nullable = true)\n",
      " |-- recommendations: string (nullable = true)\n",
      " |-- recommendedFlag: string (nullable = true)\n",
      " |-- replyCount: string (nullable = true)\n",
      " |-- reportAbuseFlag: string (nullable = true)\n",
      " |-- sectionName: string (nullable = true)\n",
      " |-- sharing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- timespeople: string (nullable = true)\n",
      " |-- trusted: string (nullable = true)\n",
      " |-- typeOfMaterial: string (nullable = true)\n",
      " |-- updateDate: string (nullable = true)\n",
      " |-- userDisplayName: string (nullable = true)\n",
      " |-- userID: string (nullable = true)\n",
      " |-- userLocation: string (nullable = true)\n",
      " |-- userTitle: string (nullable = true)\n",
      " |-- userURL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  215284\n",
      "Columns:  34\n",
      "Missing:  951911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approveDate    :  158056 \t ['1517502691', '1517495440', '1517522426', '1517505368', '1517502937']\n",
      "articleID      :  1157 \t ['5a73b2d710f40f00018bf15f', '5a75e4af10f40f00018bf58a', '5a7452df10f40f00018bf2b7', '5a749c4c10f40f00018bf38f', '5a730c8b10f40f00018bef28']\n",
      "articleWordCount:  844 \t ['1159', '800', '1372', '591', '1445']\n",
      "commentBody    :  214384 \t [\"Please take a look at photos of the crowds in attendance at women's rights marches-they are NOT entirely young women, in fact, they are a mix of young, middle age, older and include plenty of husbands, fathers and sons. Nobody is marching because it's their last chance to do so w/o being criticized, rather we are marching to ensure the equal rights of all, and sadly today that doesn't include women, but if we keep working and marching and forcing change, it will. In your families case, the caged bird sings but we protestors want to sing in the trees and skies too.\", '\"Poor Donald, I\\'m sure he\\'s so very angry with himself now that he knows he would have won the election without forking over $130,000 of that hard-earned campaign contribution cash (two criminal complaints allege), plus the fees for setting up the phony payoff company, etc.  Yes, he must be thinking \"\"I\\'m such a loser and how can I sue Stormy to get that money back\"\".<br/><br/>And while public policy birth control was being destroyed', 'I have never received a coherent answer to why the Catholic Church is against birth control.  What on earth is wrong with parents trying to control the size of their family to suit their desires and situation?  No wonder studies have shown that otherwise committed Catholics largely ignore the rule.  Some women take the pill because of unrelated medical problems.  In addition, condums reduce the likelihood spreading disease.  Some Catholics have told me it is related to preventing God’s Will.  In that case, why wear seat belts when driving?  I am not Catholic,  but I would like to know the basis for this seemingly irrational rule.', 'Seriously. How about some right-thinking millionaire back her with some real legal dough so  she can talk?', \"Go not forth in search of monsters to destroy. Why is it America is having its nose pulled by the NYT into yet another Middle Eastern conflict? What does the NYT gain from this?<br/><br/>Bring all our troops home safely, and let the Iraqis, the Kurds, the Syrians, the Turks, the Afghans, and the Pakistanis, boil in their own holy wars against each other. And especially stop handing out taxpayers' wealth to the rabid death-worshipping cults that these countries represent.\"]\n",
      "commentID      :  213415 \t ['25792117.0', '25787158.0', '25787294.0', '25785098.0', '25796425.0']\n",
      "commentSequence:  214103 \t ['25792117.0', '25787158.0', '25787294.0', '25785098.0', '25796425.0']\n",
      "commentTitle   :  35810 \t ['25787166.0', ' unless Turkey is able to remove this mentally sick fanatic. \"', ' NYTimes. The Atlantic published a full transcript of testimony about these crimes', ' not this one.  That is what is so tragically sad and cynically true.     \"', '25790535.0']\n",
      "commentType    :  27134 \t ['25787166.0', \" in America needs to address the broader issue of a country divided.  For the blue collar members of Trump's base AND for the blue collar workers who are NOT part of Trump's base\", ' but Mao believed that the USA was only \"\"the paper tiger', '25798602.0', \" I don't think certain groups are going to give up their gas guzzlers.  From what I have seen Latinos love big trucks (nothing to be ashamed of there)\"]\n",
      "createDate     :  189904 \t ['1517512813', '1517492704', '1517520679', '1517507661', '1517514344']\n",
      "depth          :  25025 \t ['1517512785', '25791575.0', ' as the recent history of Iraq and Syria teaches us. The rulers of Arab nations know this very well. And they note what has happened when they succumbed to American pressure and let their people decide', ' like siblings. Schumer has also criticized the diversity lottery so the 50', ' and worker productivity']\n",
      "editorsSelection:  18930 \t [' indeed.\"', '25791575.0', ' and they dread what might happen', '25786801.0', '1517538474']\n",
      "inReplyTo      :  46836 \t ['25784674', \" despise Trump. But let's protect our innocent Dreamers and\", '25786801.0', '25828994', '25913141']\n",
      "newDesk        :  13796 \t ['1517493386', '25913141', \" but he didn't. And he won't remove Nunes from his chairmanship\", '1517577188', '25820157.0']\n",
      "parentID       :  42189 \t ['25787166.0', '25784128.0', '25797131.0', '25794798.0', '25792939.0']\n",
      "parentUserDisplayName:  23841 \t ['RjW', 'Howard Fitzpatrick', 'zucccchini', 'Leslie374', 'Carsafrica']\n",
      "permID         :  187554 \t [' and the harasser is a powerful or valued executive', '25789525:25791328', '25796194', '25787104', '25783208:25788286']\n",
      "picURL         :  19482 \t ['25784674', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/1343/0202/cropped-13430202.jpg?0.11158927390351892', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6653/3005/cropped-66533005.jpg', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6809/0789/cropped-68090789.jpg?0.6693028591107577']\n",
      "printPage      :  12578 \t ['1517487300', '26188311', '25800129', '25798379', '25808448']\n",
      "recommendations:  10505 \t ['25784875', '25797731', '25793007', '25800133', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg']\n",
      "recommendedFlag:  7663 \t ['25794982:25799576', '25791986', '25794868', '1517658994', '25828047']\n",
      "replyCount     :  5739 \t ['1517506448', '25791986', '25811700:25850785', '1.0', '25785993']\n",
      "reportAbuseFlag:  4502 \t [' Response? One has to pretty much seek it out……as if why even take them seriously.  How can there be a clear and effective response when so few are willing to see and acknowledge how Central this issue is', '25827712.0', '1.0', '25800067', '1517582287']\n",
      "sectionName    :  3568 \t ['1.0', '25822319.0', '25795115', '25799564', '25822598']\n",
      "sharing        :  2864 \t ['25820593.0', '1.0', '25906916.0', '1517696414', '7']\n",
      "status         :  2302 \t ['25828730', '1.0', '25809776', '1517712594', '7']\n",
      "timespeople    :  1785 \t ['1.0', '1517605534', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/3081/7763/cropped-30817763.jpg', '125', '25794709']\n",
      "trusted        :  1455 \t ['25796596', '1.0', '25782241.0', ' and his minions', '7']\n",
      "typeOfMaterial :  1106 \t ['https://s3.amazonaws.com/pimage.timespeople.nytimes.com/5900/3610/cropped-59003610.jpg?0.5108037698082626', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg', '25821601:25821717', '1.0', 'News Analysis']\n",
      "updateDate     :  137568 \t ['1517495440', '1517522426', '1517505368', '1517502937', '1517512690']\n",
      "userDisplayName:  49162 \t ['RjW', 'Howard Fitzpatrick', '5barris', 'zucccchini', 'Robert Westwind']\n",
      "userID         :  65305 \t ['47942646.0', '41856854.0', '49668339.0', '12517556.0', '30990827.0']\n",
      "userLocation   :  29643 \t ['37681206.0', 'Jc Vasquez', 'Brooklyn NY', '1517784216', 'Pleasanton, CA']\n",
      "userTitle      :  14626 \t ['49668339.0', 'Athens, Ga.', 'Palermo', 'Robert Westwind', '1517503732']\n",
      "userURL        :  11403 \t ['6815766.0', 'Linda Oliver', 'Robert Westwind', 'LT', 'Charleston']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, col, count\n",
    "\n",
    "print('Rows: ', df.count())\n",
    "print('Columns: ', len(df.columns))\n",
    "print('Missing: ', df.select([\n",
    "    count(when(isnull(c),c)).alias(c) for c in df.columns])\\\n",
    "        .toPandas().sum().sum()\n",
    "    )\n",
    "for c in df.columns:\n",
    "    print(\n",
    "        '{:15}: '.format(c), df.select(c).distinct().count(), '\\t',\n",
    "        [row[c] for row in df.select(c).distinct().collect()[:5]]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-hugging')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "045ce820d34e6d6484810bfecf6086d57745e8a581b65d064e9f5f6e207f0289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
