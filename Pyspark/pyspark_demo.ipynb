{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame & SQL\n",
    "## <font color=orange>Create</font>\n",
    "* spark.read.option('header', true).option('').csv(path)\n",
    "* spark.createDataFrame(data, schema)\n",
    "### DataType\n",
    "* ArrayType  \n",
    "    - ex. StructField('name', ArrayType(StringType()), True)\n",
    "* MapType: similar python dict  \n",
    "    - ex. StructField('name', MapType(StringType(), StringType()), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\CodePratice\\Pyspark\\pyspark_demo.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dataset_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcolor\u001b[39m}\u001b[39;00m\u001b[39m_tripdata_\u001b[39m\u001b[39m{\u001b[39;00myear\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mmonth\u001b[39m:\u001b[39;00m\u001b[39m02\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dataset_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/DataTalksClub/nyc-tlc-data/releases/download/\u001b[39m\u001b[39m{\u001b[39;00mcolor\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df \u001b[39m=\u001b[39m fetch(dataset_url)\n",
      "\u001b[1;32md:\\Projects\\CodePratice\\Pyspark\\pyspark_demo.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(dataset_url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read taxi data from web into padas DataFrame\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(dataset_url,)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/CodePratice/Pyspark/pyspark_demo.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    715\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    717\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    719\u001b[0m     path_or_buf,\n\u001b[0;32m    720\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    721\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    722\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    723\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    727\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    371\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[1;32m--> 372\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[0;32m    373\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    374\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    375\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pandas\\io\\common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\james\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "color = \"yellow\"\n",
    "year = 2021\n",
    "month = 1\n",
    "dataset_file = f'{color}_tripdata_{year}-{month:02}'\n",
    "dataset_url = f\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/{color}/{dataset_file}\"\n",
    "def fetch(dataset_url: str) -> pd.DataFrame:\n",
    "    \"\"\"Read taxi data from web into padas DataFrame\"\"\"\n",
    "    df = pd.read_csv(dataset_url,)\n",
    "    return df\n",
    "df = fetch(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emptyRDD:  ParallelCollectionRDD[1] at readRDDFromFile at PythonRDD.scala:274\n",
      "Convert DataFrame from emptyRDD\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n",
      "root\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Demo').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('WARN')\n",
    "\n",
    "# empty RDD\n",
    "emptyRDD = sc.emptyRDD()\n",
    "emptyRDD = sc.parallelize([])\n",
    "print(\"emptyRDD: \",emptyRDD)\n",
    "\n",
    "# Create Schema\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, ArrayType, MapType\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('firstname', StringType(), True),\n",
    "    StructField('middlename', StringType(), True),\n",
    "    StructField('lastname', StringType(), True)\n",
    "])\n",
    "\n",
    "# Convert Dataframe from emptyRDD\n",
    "df = spark.createDataFrame(data=emptyRDD, schema=schema)\n",
    "print('Convert DataFrame from emptyRDD')\n",
    "df.printSchema()\n",
    "\n",
    "# Create DataFrame from schema\n",
    "df2 = spark.createDataFrame([], schema)\n",
    "df2.printSchema()\n",
    "\n",
    "# Create empty DF with no schema\n",
    "df3 = spark.createDataFrame([],StructType([]))\n",
    "df3.printSchema()\n",
    "\n",
    "# convert DF to pandas\n",
    "df_pandas = df.toPandas()\n",
    "type(df_pandas), type(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|{James, , Smith}    |36636|M     |3100  |\n",
      "|{Michael, Rose, }   |40288|M     |4300  |\n",
      "|{Robert, , Williams}|42114|M     |1400  |\n",
      "|{Maria, Anne, Jones}|39192|F     |5500  |\n",
      "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n",
      "+--------------------+------------------------+\n",
      "|name                |OtherInfo               |\n",
      "+--------------------+------------------------+\n",
      "|{James, , Smith}    |{36636, M, 3100, Medium}|\n",
      "|{Michael, Rose, }   |{40288, M, 4300, High}  |\n",
      "|{Robert, , Williams}|{42114, M, 1400, Low}   |\n",
      "|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n",
      "|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n",
      "+--------------------+------------------------+\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|                name|   id|gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|    {James, , Smith}|36636|     M|  3100|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|\n",
      "|{Robert, , Williams}|42114|     M|  1400|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, struct, when, lit\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)\n",
    "\n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "    struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)\n",
    "\n",
    "import json\n",
    "schemaFromJson = StructType.fromJson(json.loads(structureSchema.json()))\n",
    "df3 = spark.createDataFrame(\n",
    "    sc.parallelize(structureData), schemaFromJson)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'struct<name:struct<firstname:string,middlename:string,lastname:string>,id:string,gender:string,salary:int>'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.schema.simpleString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/drop `TempView`\n",
    "1. Create\n",
    "  * Global: \n",
    "    ```python\n",
    "    df.createOrReplaceGlobalTempView('TableName')\n",
    "    spark.sql(\"select * from global_temp.TableName\")\n",
    "    ```\n",
    "  * Local:  \n",
    "    ```python\n",
    "    df.createOrReplaceTempView('TableName')\n",
    "    spark.sql(\"select * from TableName)\n",
    "    ```\n",
    "2. Drop\n",
    "  * spark.catalog.dropGlobalTempView('TableName')\n",
    "  * spark.catalog.dropTempView('TableName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name=Row(firstname='James', middlename='', lastname='Smith'), id='36636', gender='M', salary=3100), Row(name=Row(firstname='Michael', middlename='Rose', lastname=''), id='40288', gender='M', salary=4300), Row(name=Row(firstname='Robert', middlename='', lastname='Williams'), id='42114', gender='M', salary=1400), Row(name=Row(firstname='Maria', middlename='Anne', lastname='Jones'), id='39192', gender='F', salary=5500), Row(name=Row(firstname='Jen', middlename='Mary', lastname='Brown'), id='', gender='F', salary=-1)]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df2.createOrReplaceTempView('tmp_df2')\n",
    "print(spark.sql('select * from tmp_df2 ').collect())\n",
    "print(spark.catalog.dropTempView('tmp_df2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange>Update</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 新增欄位 \n",
    "* 新增或替換現有的欄位 withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+------+-------+\n",
      "|                name|   id|gender|salary|new_col|\n",
      "+--------------------+-----+------+------+-------+\n",
      "|    {James, , Smith}|36636|     M|  3100|      0|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|      0|\n",
      "|{Robert, , Williams}|42114|     M|  1400|      0|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|      0|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|      0|\n",
      "+--------------------+-----+------+------+-------+\n",
      "\n",
      "+--------------------+-----+------+------+--------+\n",
      "|                name|   id|gender|salary|  new_co|\n",
      "+--------------------+-----+------+------+--------+\n",
      "|    {James, , Smith}|36636|     M|  3100|over2000|\n",
      "|   {Michael, Rose, }|40288|     M|  4300|over2000|\n",
      "|{Robert, , Williams}|42114|     M|  1400|    1400|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500|over2000|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|   error|\n",
      "+--------------------+-----+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "#1 新增欄位輸入值 要用lit\n",
    "df2.withColumn('new_col', lit(0)).show()\n",
    "\n",
    "#2 依現有欄位條件輸入新欄位\n",
    "df2.withColumn('new_co', when(df2.salary<0,'error'). \\\n",
    "                         when(df2.salary==1400, '1400'). \\\n",
    "                         when(df2.salary.between(0,2000),'0-2000'). \\\n",
    "                         otherwise('over2000')).show()\n",
    "#3 新增一個list 轉為spark dataframe 再join\n",
    "# 目前尚未找到類似pd.concat功能\n",
    "\n",
    "id = F.monotonically_increasing_id()\n",
    "row = Row('val', 'num')\n",
    "lt = lt = [row(f'x{i}',i) for i in range(5)]\n",
    "sc_lt = spark.sparkContext.parallelize(lt).toDF()\n",
    "sc_lt = sc_lt.withColumn('matchID', id)\n",
    "df2_new = df2.withColumn('matchID',id)\n",
    "df3 = df2_new.join(sc_lt, df2_new.matchID == sc_lt.matchID, how='inner').drop('matchID')\n",
    "df3 = df3.withColumn('newid', when(df3.id=='',None).otherwise(df3.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 條件篩選"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+------+---+---+-----+\n",
      "|              name| id|gender|salary|val|num|newid|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|{Jen, Mary, Brown}|   |     F|    -1| x4|  4| null|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "|                name|   id|gender|salary|val|num|newid|\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "|    {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|   {Michael, Rose, }|40288|     M|  4300| x1|  1|40288|\n",
      "|{Robert, , Williams}|42114|     M|  1400| x2|  2|42114|\n",
      "|{Maria, Anne, Jones}|39192|     F|  5500| x3|  3|39192|\n",
      "+--------------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "|             name|   id|gender|salary|val|num|newid|\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "| {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|{Michael, Rose, }|40288|     M|  4300| x1|  1|40288|\n",
      "+-----------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "|              name|   id|gender|salary|val|num|newid|\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "|  {James, , Smith}|36636|     M|  3100| x0|  0|36636|\n",
      "|{Jen, Mary, Brown}|     |     F|    -1| x4|  4| null|\n",
      "+------------------+-----+------+------+---+---+-----+\n",
      "\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|              name| id|gender|salary|val|num|newid|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "|{Jen, Mary, Brown}|   |     F|    -1| x4|  4| null|\n",
      "+------------------+---+------+------+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "df3.filter(df3.salary<0).show()\n",
    "# where \n",
    "df3.where(df3.salary>0).show()\n",
    "# between\n",
    "df3.filter(df3.salary.between(3100,4400)).show()\n",
    "# isin\n",
    "df3[df3.salary.isin([3100,-1])].show()\n",
    "# isnull(None) / isnan(非數字)\n",
    "df3.filter(F.isnull('newid')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Rename column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "\n",
    "# Example 1\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()\n",
    "# Example 2   \n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "\n",
    "# Example 3 \n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "    \n",
    "df.select(col(\"name\").cast(schema2),\n",
    "  col(\"dob\"),\n",
    "  col(\"gender\"),\n",
    "  col(\"salary\")) \\\n",
    "    .printSchema()    \n",
    "\n",
    "# Example 4 \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "  col(\"name.middlename\").alias(\"mname\"),\n",
    "  col(\"name.lastname\").alias(\"lname\"),\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()\n",
    "  \n",
    "# Example 5\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()\n",
    "\n",
    "#Example 7\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/13 23:56:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Demo').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "    .option('header',True)\\\n",
    "    .option('inferSchema',True)\\\n",
    "    .csv(\"./archive/CommentsFeb2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- approveDate: string (nullable = true)\n",
      " |-- articleID: string (nullable = true)\n",
      " |-- articleWordCount: string (nullable = true)\n",
      " |-- commentBody: string (nullable = true)\n",
      " |-- commentID: string (nullable = true)\n",
      " |-- commentSequence: string (nullable = true)\n",
      " |-- commentTitle: string (nullable = true)\n",
      " |-- commentType: string (nullable = true)\n",
      " |-- createDate: string (nullable = true)\n",
      " |-- depth: string (nullable = true)\n",
      " |-- editorsSelection: string (nullable = true)\n",
      " |-- inReplyTo: string (nullable = true)\n",
      " |-- newDesk: string (nullable = true)\n",
      " |-- parentID: string (nullable = true)\n",
      " |-- parentUserDisplayName: string (nullable = true)\n",
      " |-- permID: string (nullable = true)\n",
      " |-- picURL: string (nullable = true)\n",
      " |-- printPage: string (nullable = true)\n",
      " |-- recommendations: string (nullable = true)\n",
      " |-- recommendedFlag: string (nullable = true)\n",
      " |-- replyCount: string (nullable = true)\n",
      " |-- reportAbuseFlag: string (nullable = true)\n",
      " |-- sectionName: string (nullable = true)\n",
      " |-- sharing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- timespeople: string (nullable = true)\n",
      " |-- trusted: string (nullable = true)\n",
      " |-- typeOfMaterial: string (nullable = true)\n",
      " |-- updateDate: string (nullable = true)\n",
      " |-- userDisplayName: string (nullable = true)\n",
      " |-- userID: string (nullable = true)\n",
      " |-- userLocation: string (nullable = true)\n",
      " |-- userTitle: string (nullable = true)\n",
      " |-- userURL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  215284\n",
      "Columns:  34\n",
      "Missing:  951911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approveDate    :  158056 \t ['1517502691', '1517495440', '1517522426', '1517505368', '1517502937']\n",
      "articleID      :  1157 \t ['5a73b2d710f40f00018bf15f', '5a75e4af10f40f00018bf58a', '5a7452df10f40f00018bf2b7', '5a749c4c10f40f00018bf38f', '5a730c8b10f40f00018bef28']\n",
      "articleWordCount:  844 \t ['1159', '800', '1372', '591', '1445']\n",
      "commentBody    :  214384 \t [\"Please take a look at photos of the crowds in attendance at women's rights marches-they are NOT entirely young women, in fact, they are a mix of young, middle age, older and include plenty of husbands, fathers and sons. Nobody is marching because it's their last chance to do so w/o being criticized, rather we are marching to ensure the equal rights of all, and sadly today that doesn't include women, but if we keep working and marching and forcing change, it will. In your families case, the caged bird sings but we protestors want to sing in the trees and skies too.\", '\"Poor Donald, I\\'m sure he\\'s so very angry with himself now that he knows he would have won the election without forking over $130,000 of that hard-earned campaign contribution cash (two criminal complaints allege), plus the fees for setting up the phony payoff company, etc.  Yes, he must be thinking \"\"I\\'m such a loser and how can I sue Stormy to get that money back\"\".<br/><br/>And while public policy birth control was being destroyed', 'I have never received a coherent answer to why the Catholic Church is against birth control.  What on earth is wrong with parents trying to control the size of their family to suit their desires and situation?  No wonder studies have shown that otherwise committed Catholics largely ignore the rule.  Some women take the pill because of unrelated medical problems.  In addition, condums reduce the likelihood spreading disease.  Some Catholics have told me it is related to preventing God’s Will.  In that case, why wear seat belts when driving?  I am not Catholic,  but I would like to know the basis for this seemingly irrational rule.', 'Seriously. How about some right-thinking millionaire back her with some real legal dough so  she can talk?', \"Go not forth in search of monsters to destroy. Why is it America is having its nose pulled by the NYT into yet another Middle Eastern conflict? What does the NYT gain from this?<br/><br/>Bring all our troops home safely, and let the Iraqis, the Kurds, the Syrians, the Turks, the Afghans, and the Pakistanis, boil in their own holy wars against each other. And especially stop handing out taxpayers' wealth to the rabid death-worshipping cults that these countries represent.\"]\n",
      "commentID      :  213415 \t ['25792117.0', '25787158.0', '25787294.0', '25785098.0', '25796425.0']\n",
      "commentSequence:  214103 \t ['25792117.0', '25787158.0', '25787294.0', '25785098.0', '25796425.0']\n",
      "commentTitle   :  35810 \t ['25787166.0', ' unless Turkey is able to remove this mentally sick fanatic. \"', ' NYTimes. The Atlantic published a full transcript of testimony about these crimes', ' not this one.  That is what is so tragically sad and cynically true.     \"', '25790535.0']\n",
      "commentType    :  27134 \t ['25787166.0', \" in America needs to address the broader issue of a country divided.  For the blue collar members of Trump's base AND for the blue collar workers who are NOT part of Trump's base\", ' but Mao believed that the USA was only \"\"the paper tiger', '25798602.0', \" I don't think certain groups are going to give up their gas guzzlers.  From what I have seen Latinos love big trucks (nothing to be ashamed of there)\"]\n",
      "createDate     :  189904 \t ['1517512813', '1517492704', '1517520679', '1517507661', '1517514344']\n",
      "depth          :  25025 \t ['1517512785', '25791575.0', ' as the recent history of Iraq and Syria teaches us. The rulers of Arab nations know this very well. And they note what has happened when they succumbed to American pressure and let their people decide', ' like siblings. Schumer has also criticized the diversity lottery so the 50', ' and worker productivity']\n",
      "editorsSelection:  18930 \t [' indeed.\"', '25791575.0', ' and they dread what might happen', '25786801.0', '1517538474']\n",
      "inReplyTo      :  46836 \t ['25784674', \" despise Trump. But let's protect our innocent Dreamers and\", '25786801.0', '25828994', '25913141']\n",
      "newDesk        :  13796 \t ['1517493386', '25913141', \" but he didn't. And he won't remove Nunes from his chairmanship\", '1517577188', '25820157.0']\n",
      "parentID       :  42189 \t ['25787166.0', '25784128.0', '25797131.0', '25794798.0', '25792939.0']\n",
      "parentUserDisplayName:  23841 \t ['RjW', 'Howard Fitzpatrick', 'zucccchini', 'Leslie374', 'Carsafrica']\n",
      "permID         :  187554 \t [' and the harasser is a powerful or valued executive', '25789525:25791328', '25796194', '25787104', '25783208:25788286']\n",
      "picURL         :  19482 \t ['25784674', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/1343/0202/cropped-13430202.jpg?0.11158927390351892', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6653/3005/cropped-66533005.jpg', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6809/0789/cropped-68090789.jpg?0.6693028591107577']\n",
      "printPage      :  12578 \t ['1517487300', '26188311', '25800129', '25798379', '25808448']\n",
      "recommendations:  10505 \t ['25784875', '25797731', '25793007', '25800133', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg']\n",
      "recommendedFlag:  7663 \t ['25794982:25799576', '25791986', '25794868', '1517658994', '25828047']\n",
      "replyCount     :  5739 \t ['1517506448', '25791986', '25811700:25850785', '1.0', '25785993']\n",
      "reportAbuseFlag:  4502 \t [' Response? One has to pretty much seek it out……as if why even take them seriously.  How can there be a clear and effective response when so few are willing to see and acknowledge how Central this issue is', '25827712.0', '1.0', '25800067', '1517582287']\n",
      "sectionName    :  3568 \t ['1.0', '25822319.0', '25795115', '25799564', '25822598']\n",
      "sharing        :  2864 \t ['25820593.0', '1.0', '25906916.0', '1517696414', '7']\n",
      "status         :  2302 \t ['25828730', '1.0', '25809776', '1517712594', '7']\n",
      "timespeople    :  1785 \t ['1.0', '1517605534', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/3081/7763/cropped-30817763.jpg', '125', '25794709']\n",
      "trusted        :  1455 \t ['25796596', '1.0', '25782241.0', ' and his minions', '7']\n",
      "typeOfMaterial :  1106 \t ['https://s3.amazonaws.com/pimage.timespeople.nytimes.com/5900/3610/cropped-59003610.jpg?0.5108037698082626', 'https://s3.amazonaws.com/pimage.timespeople.nytimes.com/6005/3415/cropped-60053415.jpg', '25821601:25821717', '1.0', 'News Analysis']\n",
      "updateDate     :  137568 \t ['1517495440', '1517522426', '1517505368', '1517502937', '1517512690']\n",
      "userDisplayName:  49162 \t ['RjW', 'Howard Fitzpatrick', '5barris', 'zucccchini', 'Robert Westwind']\n",
      "userID         :  65305 \t ['47942646.0', '41856854.0', '49668339.0', '12517556.0', '30990827.0']\n",
      "userLocation   :  29643 \t ['37681206.0', 'Jc Vasquez', 'Brooklyn NY', '1517784216', 'Pleasanton, CA']\n",
      "userTitle      :  14626 \t ['49668339.0', 'Athens, Ga.', 'Palermo', 'Robert Westwind', '1517503732']\n",
      "userURL        :  11403 \t ['6815766.0', 'Linda Oliver', 'Robert Westwind', 'LT', 'Charleston']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnull, when, col, count\n",
    "\n",
    "print('Rows: ', df.count())\n",
    "print('Columns: ', len(df.columns))\n",
    "print('Missing: ', df.select([\n",
    "    count(when(isnull(c),c)).alias(c) for c in df.columns])\\\n",
    "        .toPandas().sum().sum()\n",
    "    )\n",
    "for c in df.columns:\n",
    "    print(\n",
    "        '{:15}: '.format(c), df.select(c).distinct().count(), '\\t',\n",
    "        [row[c] for row in df.select(c).distinct().collect()[:5]]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
